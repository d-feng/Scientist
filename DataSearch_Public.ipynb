{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da394f9c-9974-4e5d-8b55-e4c80acda7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "from agents import Agent, Runner\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from bs4 import BeautifulSoup\n",
    "API_KEY = ''\n",
    "os.environ['OPENAI_API_KEY']=API_KEY\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7189bab1-8f4d-468a-85cf-021fd14bb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import TypedDict, List, Dict, Any\n",
    "from bs4 import BeautifulSoup\n",
    "from geofetch import Geofetcher\n",
    "from openai import OpenAI\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# ----------------------------------------\n",
    "# Agent state schema\n",
    "# ----------------------------------------\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query_gene: str\n",
    "    pathway_info: Dict[str, Any]\n",
    "    metadata: Dict[str, Any]\n",
    "    gse_list: List[str]\n",
    "    research_plan: str\n",
    "\n",
    "# ----------------------------------------\n",
    "# Utility functions (LLM + GEO search)\n",
    "# ----------------------------------------\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def extract_json_block(text):\n",
    "    match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", text, re.DOTALL)\n",
    "    if match:\n",
    "        return json.loads(match.group(1))\n",
    "    else:\n",
    "        return json.loads(text)\n",
    "\n",
    "def generate_pathway_info(query_gene, model=\"gpt-4o-mini\", temperature=0.3):\n",
    "    prompt = f\"\"\"\n",
    "You are a biomedical assistant.\n",
    "\n",
    "Given the gene {query_gene}, return:\n",
    "1. Key gene symbols in the same biological pathway.\n",
    "2. Drugs or compounds that inhibit this pathway or {query_gene}'s activity.\n",
    "3. The disease areas or biological processes this pathway is involved in.\n",
    "\n",
    "Provide answers in JSON format with keys: \"genes\", \"drugs\", \"pathways\"\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    content = completion.choices[0].message.content\n",
    "    return extract_json_block(content)\n",
    "\n",
    "def scrape_organism_from_geo_html(geo_accession):\n",
    "    url = f\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={geo_accession}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        organism_row = soup.find(\"td\", string=\"Organism\")\n",
    "        if organism_row and organism_row.find_next_sibling(\"td\"):\n",
    "            return organism_row.find_next_sibling(\"td\").text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to scrape organism for {geo_accession}: {e}\")\n",
    "    return \"Unknown\"\n",
    "\n",
    "def search_geo_datasets(keyword, retmax=10):\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    params = {\n",
    "        \"db\": \"gds\",\n",
    "        \"term\": keyword,\n",
    "        \"retmode\": \"json\",\n",
    "        \"retmax\": retmax\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json().get(\"esearchresult\", {}).get(\"idlist\", [])\n",
    "\n",
    "def fetch_gse_accessions(id_list):\n",
    "    if not id_list:\n",
    "        return {}\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\"\n",
    "    params = {\n",
    "        \"db\": \"gds\",\n",
    "        \"id\": \",\".join(id_list),\n",
    "        \"retmode\": \"json\"\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    summaries = response.json().get(\"result\", {})\n",
    "    summaries.pop(\"uids\", None)\n",
    "    gse_dict = {}\n",
    "    for uid, info in summaries.items():\n",
    "        accession = info.get(\"accession\")\n",
    "        title = info.get(\"title\")\n",
    "        link = f\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={accession}\"\n",
    "        organism = scrape_organism_from_geo_html(accession)\n",
    "        gse_dict[accession] = {\n",
    "            \"title\": title,\n",
    "            \"organism\": organism,\n",
    "            \"link\": link\n",
    "        }\n",
    "    return gse_dict\n",
    "\n",
    "def search_geo_items(item_list, label=\"gene\", max_results=5):\n",
    "    results = {}\n",
    "    for item in item_list:\n",
    "        query = f\"{item} AND rna-seq\"\n",
    "        print(f\"🔍 Searching GEO for {label}: {item}\")\n",
    "        ids = search_geo_datasets(query, retmax=max_results)\n",
    "        datasets = fetch_gse_accessions(ids)\n",
    "        results[item] = datasets\n",
    "        time.sleep(0.3)\n",
    "    return results\n",
    "\n",
    "def get_geofetch_projects(gse_list, metadata_folder=\"geofetch_metadata\"):\n",
    "    geof = Geofetcher(\n",
    "        processed=True,\n",
    "        acc_anno=True,\n",
    "        discard_soft=True,\n",
    "        metadata_folder=metadata_folder\n",
    "    )\n",
    "    projects = {}\n",
    "    for gse in gse_list:\n",
    "        try:\n",
    "            print(f\"📥 Fetching metadata for {gse}\")\n",
    "            result = geof.get_projects(gse)\n",
    "            projects.update(result)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to fetch {gse}: {e}\")\n",
    "    return projects\n",
    "\n",
    "import subprocess\n",
    "def download_processed_files_via_cli(gse_list, output_dir=\"geofetch_metadata\", overwrite=False):\n",
    "    for gse in gse_list:\n",
    "        gse_path = os.path.join(output_dir, gse)\n",
    "        if os.path.exists(gse_path) and not overwrite:\n",
    "            print(f\"✅ {gse}: already exists at {gse_path}, skipping.\")\n",
    "            continue\n",
    "        try:\n",
    "            subprocess.run(\n",
    "                [\"geofetch\", \"-i\", gse, \"--processed\", \"-m\", output_dir],\n",
    "                check=True\n",
    "            )\n",
    "            print(f\"✅ Finished downloading for {gse}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"❌ geofetch failed for {gse}: {e}\")\n",
    "\n",
    "def save_combined_metadata_csv_from_state(state: Dict, csv_path: str = \"geofetch_metadata/combined_metadata.csv\") -> pd.DataFrame:\n",
    "    metadata = state.get(\"metadata\", {})\n",
    "    if not metadata:\n",
    "        raise ValueError(\"No metadata found in the agent state.\")\n",
    "\n",
    "    all_dfs = []\n",
    "    for gse, project in metadata.items():\n",
    "        try:\n",
    "            df = project.sample_table.copy()\n",
    "            df[\"source_gse\"] = gse\n",
    "            all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to extract sample_table from {gse}: {e}\")\n",
    "\n",
    "    if not all_dfs:\n",
    "        raise ValueError(\"No sample tables to save.\")\n",
    "\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    combined_df.to_csv(csv_path, index=False)\n",
    "    print(f\"✅ Combined metadata saved to: {os.path.abspath(csv_path)}\")\n",
    "    return combined_df\n",
    "\n",
    "# ----------------------------------------\n",
    "# Agent 1: Ingestor node\n",
    "# ----------------------------------------\n",
    "\n",
    "def ingest_and_prepare(state: dict) -> dict:\n",
    "    query_gene = state[\"query_gene\"]\n",
    "    pathway_info = generate_pathway_info(query_gene)\n",
    "    gene_list = pathway_info.get(\"genes\", [])\n",
    "    drug_list = pathway_info.get(\"drugs\", [])\n",
    "\n",
    "    gene_results = search_geo_items(gene_list, label=\"gene\")\n",
    "    drug_results = search_geo_items(drug_list, label=\"drug\")\n",
    "\n",
    "    all_gse = set()\n",
    "    for r in [gene_results, drug_results]:\n",
    "        for v in r.values():\n",
    "            all_gse.update(v.keys())\n",
    "    all_gse = list(all_gse)\n",
    "\n",
    "    metadata = get_geofetch_projects(all_gse, metadata_folder=\"geofetch_metadata\")\n",
    "    download_processed_files_via_cli(all_gse, output_dir=\"geofetch_metadata\")\n",
    "\n",
    "    try:\n",
    "        save_combined_metadata_csv_from_state({\"metadata\": metadata})\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to save metadata CSV: {e}\")\n",
    "\n",
    "    return {\n",
    "        \"query_gene\": query_gene,\n",
    "        \"pathway_info\": pathway_info,\n",
    "        \"metadata\": metadata,\n",
    "        \"gse_list\": all_gse\n",
    "    }\n",
    "\n",
    "# ----------------------------------------\n",
    "# Agent 2: Analyst node\n",
    "# ----------------------------------------\n",
    "\n",
    "def analyze_metadata_and_plan(state: AgentState) -> AgentState:\n",
    "    metadata = state[\"metadata\"]\n",
    "    drug_list = state[\"pathway_info\"].get(\"drugs\", [])\n",
    "    query_gene = state[\"query_gene\"]\n",
    "    selected = []\n",
    "\n",
    "    for gse, project in metadata.items():\n",
    "        df = project.sample_table\n",
    "        if \"processed_file_ftp\" in df.columns and df[\"processed_file_ftp\"].notna().any():\n",
    "            if any(drug.lower() in df.to_string().lower() for drug in drug_list):\n",
    "                selected.append((gse, df.shape[0]))\n",
    "\n",
    "    plan = f\"🧬 Research Plan for {query_gene} and drugs {drug_list}:\\n\"\n",
    "    if not selected:\n",
    "        plan += \"No relevant processed datasets were found.\\n\"\n",
    "    else:\n",
    "        plan += f\"{len(selected)} datasets selected:\\n\"\n",
    "        for gse, n in selected:\n",
    "            plan += f\"  - {gse} ({n} samples)\\n\"\n",
    "        plan += \"\\nNext: perform differential expression and gene signature clustering.\"\n",
    "\n",
    "    return {**state, \"research_plan\": plan}\n",
    "\n",
    "\n",
    "def analyze_metadata_and_plan(state: AgentState) -> AgentState:\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    csv_path = \"geofetch_metadata/combined_metadata.csv\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"❌ Metadata CSV not found at {csv_path}\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    required_columns = {\"sample_name\", \"sample_source_name_ch1\", \"sample_title\"}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        raise ValueError(f\"❌ Metadata CSV must include columns: {required_columns}\")\n",
    "\n",
    "    # Take first 50 rows for LLM context\n",
    "    selected_df = df[list(required_columns)].fillna(\"\").head(50)\n",
    "    table_preview = selected_df.to_markdown(index=False)\n",
    "\n",
    "    query_gene = state[\"query_gene\"]\n",
    "    drug_list = state[\"pathway_info\"].get(\"drugs\", [])\n",
    "    selected_df = df[[\"sample_name\", \"sample_source_name_ch1\", \"sample_title\"]].fillna(\"\").head(50)\n",
    "    table_preview = selected_df.to_markdown(index=False)\n",
    "    print(\"🧪 Table preview sent to LLM:\\n\", table_preview)  # ✅ Add this line\n",
    "\n",
    "    # Build LLM prompt\n",
    "    prompt = f\"\"\"\n",
    "You are a biomedical research assistant.\n",
    "\n",
    "The target gene is **{query_gene}**, and the related drugs of interest are: {', '.join(drug_list)}.\n",
    "\n",
    "Below is a preview of sample metadata (first 50 rows) from multiple GEO studies. Each row includes:\n",
    "- sample name\n",
    "- sample source (cell line, tissue)\n",
    "- sample title (may indicate treatment or condition)\n",
    "\n",
    "Your task:\n",
    "1. Identify which studies include drug-treated samples.\n",
    "2. Identify the control groups if available.\n",
    "3. Determine the sample types (e.g., cell lines or tissues).\n",
    "4. Recommend studies and sample comparisons suitable for differential gene expression and drug-response signature analysis.\n",
    "\n",
    "Respond with:\n",
    "- GSE or study names (if known)\n",
    "- The experimental comparison design\n",
    "- Why the dataset is suitable (or not)\n",
    "- Bullet points summarizing each recommended comparison\n",
    "\n",
    "Sample Metadata Table:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Call LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.3,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    research_plan = response.choices[0].message.content.strip()\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"research_plan\": research_plan\n",
    "    }\n",
    "\n",
    "###\n",
    "def analyze_metadata_and_plan(state: AgentState) -> AgentState:\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    csv_path = \"geofetch_metadata/combined_metadata.csv\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"❌ Metadata CSV not found at {csv_path}\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Ensure required columns are available\n",
    "    required_cols = [\"gse\", \"sample_name\", \"sample_title\", \"sample_source_name_ch1\", \"sample_geo_accession\"]\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        raise ValueError(f\"❌ Metadata CSV must contain the following columns: {required_cols}\")\n",
    "\n",
    "    # Clean and preview first 30 rows\n",
    "    preview_df = df[required_cols].fillna(\"\").head(30)\n",
    "    preview_text = preview_df.to_string(index=False)\n",
    "\n",
    "    query_gene = state[\"query_gene\"]\n",
    "    drug_list = state[\"pathway_info\"].get(\"drugs\", [])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a biomedical research assistant.\n",
    "\n",
    "The target gene is **{query_gene}** and the related drugs of interest are: {', '.join(drug_list)}.\n",
    "\n",
    "Below is a preview of sample metadata from several GEO datasets.\n",
    "Each row includes:\n",
    "- GSE accession\n",
    "- Sample name\n",
    "- Sample title (may contain treatment or control info)\n",
    "- Sample source (cell type or tissue)\n",
    "- Sample GEO accession\n",
    "\n",
    "Sample Metadata Table:\n",
    "{preview_text}\n",
    "\n",
    "Based on the sample names, titles, and sources:\n",
    "1. Which GSE studies contain drug-treated samples and matching control groups?\n",
    "2. What cell types or tissues are used?\n",
    "3. Which treatments are applied? What are the controls?\n",
    "4. Recommend GSEs and sample pairs suitable for differential gene expression to identify drug-response gene signatures.\n",
    "\n",
    "Be specific, refer to GSE and sample names where possible, and explain why you recommend them.\n",
    "\"\"\"\n",
    "\n",
    "    # Call OpenAI LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.3,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    research_plan = response.choices[0].message.content.strip()\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"research_plan\": research_plan\n",
    "    }\n",
    "\n",
    "# ----------------------------------------\n",
    "# LangGraph pipeline\n",
    "# ----------------------------------------\n",
    "\n",
    "workflow = StateGraph(state_schema=AgentState)\n",
    "workflow.add_node(\"Ingestor\", RunnableLambda(ingest_and_prepare))\n",
    "workflow.add_node(\"Analyst\", RunnableLambda(analyze_metadata_and_plan))\n",
    "workflow.set_entry_point(\"Ingestor\")\n",
    "workflow.add_edge(\"Ingestor\", \"Analyst\")\n",
    "workflow.set_finish_point(\"Analyst\")\n",
    "graph = workflow.compile()\n",
    "\n",
    "# ----------------------------------------\n",
    "# Invoke the graph\n",
    "# ----------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6f86e31-7ce2-4491-bca7-2655eb794cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4669ebdb-55b6-4699-a95c-1e90468295a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Searching GEO for gene: PTGS2\n",
      "🔍 Searching GEO for gene: PTGS1\n",
      "🔍 Searching GEO for gene: ALOX5\n",
      "🔍 Searching GEO for gene: CYP2C9\n",
      "🔍 Searching GEO for gene: CYP2C19\n",
      "🔍 Searching GEO for drug: Aspirin\n",
      "🔍 Searching GEO for drug: Ibuprofen\n",
      "🔍 Searching GEO for drug: Naproxen\n",
      "🔍 Searching GEO for drug: Celecoxib\n",
      "🔍 Searching GEO for drug: Diclofenac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:44]\u001b[0m Metadata folder: C:\\Users\\difen\\POPPER\\geofetch_metadata\\project_name\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:44]\u001b[0m Trying GSE120596 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:44]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE120596'\u001b[0m\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:44]\u001b[0m Trying GSE120596 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:44]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:44]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE120596'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE120596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:53]\u001b[0m Total number of processed SERIES files found is: 2\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:53]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:53]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:53]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:53]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:53]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE120596_samples\\GSE120596_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:53]\u001b[0m Trying GSE156453 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:53]\u001b[0m Trying GSE156453 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:53]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:53]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE156453'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE156453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:56]\u001b[0m Total number of processed SERIES files found is: 2\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:56]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:56]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:56]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:56]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:56]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE156453_samples\\GSE156453_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:56]\u001b[0m Trying GSE279800 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:56]\u001b[0m Trying GSE279800 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:56]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:56]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE279800'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE279800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:57]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 8\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:57]\u001b[0m Total number of processed SERIES files found is: 0\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:57]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:57]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:57]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:57]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:57]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:57]\u001b[0m Trying GSE242272 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:57]\u001b[0m Trying GSE242272 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:57]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:48:57]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE242272'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE242272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:00]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 18\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:00]\u001b[0m Total number of processed SERIES files found is: 0\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:00]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:00]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:00]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:00]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:00]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:00]\u001b[0m Trying GSE139044 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:00]\u001b[0m Trying GSE139044 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:00]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:00]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE139044'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE139044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:03]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:03]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:03]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:03]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:03]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:03]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE139044_samples\\GSE139044_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:03]\u001b[0m Trying GSE124074 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:03]\u001b[0m Trying GSE124074 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:03]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:03]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE124074'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE124074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:07]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 60\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:07]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:07]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:07]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:07]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:07]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:07]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:07]\u001b[0m Trying GSE245768 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:07]\u001b[0m Trying GSE245768 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:07]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:07]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE245768'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE245768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:10]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 15\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:10]\u001b[0m Total number of processed SERIES files found is: 0\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:10]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:10]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:10]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:10]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:10]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:10]\u001b[0m Trying GSE180857 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:10]\u001b[0m Trying GSE180857 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:10]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:10]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE180857'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE180857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:14]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 31\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:14]\u001b[0m Total number of processed SERIES files found is: 0\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:14]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:14]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:14]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:14]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:14]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:14]\u001b[0m Trying GSE131732 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:14]\u001b[0m Trying GSE131732 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:14]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:14]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE131732'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE131732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:17]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:17]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:17]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:17]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:17]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:17]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE131732_samples\\GSE131732_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:17]\u001b[0m Trying GSE242369 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:17]\u001b[0m Trying GSE242369 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:17]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:17]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE242369'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE242369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:21]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:21]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:21]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:21]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:21]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:21]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE242369_samples\\GSE242369_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:21]\u001b[0m Trying GSE110282 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:21]\u001b[0m Trying GSE110282 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:21]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:21]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE110282'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE110282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:23]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:23]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:23]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:23]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:23]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:23]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE110282_samples\\GSE110282_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:23]\u001b[0m Trying GSE278083 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:23]\u001b[0m Trying GSE278083 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:23]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:23]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE278083'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE278083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:25]\u001b[0m Total number of processed SERIES files found is: 4\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:25]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:25]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:25]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:25]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:25]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE278083_samples\\GSE278083_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:25]\u001b[0m Trying GSE175744 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:25]\u001b[0m Trying GSE175744 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:25]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:25]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE175744'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE175744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:33]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:33]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:33]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:33]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:33]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:33]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE175744_samples\\GSE175744_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:33]\u001b[0m Trying GSE184884 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:33]\u001b[0m Trying GSE184884 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:33]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:49:33]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE184884'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE184884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:00]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 197\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:00]\u001b[0m Total number of processed SERIES files found is: 3\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:00]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:00]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:00]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:00]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:00]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:00]\u001b[0m Trying GSE38809 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:00]\u001b[0m Trying GSE38809 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:00]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:00]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE38809'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE38809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:02]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 3\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:02]\u001b[0m Total number of processed SERIES files found is: 3\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:02]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:02]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:02]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:02]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:02]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:02]\u001b[0m Trying GSE222593 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:02]\u001b[0m Trying GSE222593 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:02]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:02]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE222593'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE222593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:47]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 355\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:47]\u001b[0m Total number of processed SERIES files found is: 6\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:47]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:47]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:47]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:47]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:47]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:48]\u001b[0m Trying GSE262419 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:48]\u001b[0m Trying GSE262419 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:48]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:50:48]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE262419'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE262419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:33]\u001b[0m Total number of processed SERIES files found is: 17\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:33]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:33]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:33]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:33]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:33]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE262419_samples\\GSE262419_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:33]\u001b[0m Trying GSE97066 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:33]\u001b[0m Trying GSE97066 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:33]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:33]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE97066'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE97066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:37]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:37]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:37]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:37]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:37]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:37]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE97066_samples\\GSE97066_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:37]\u001b[0m Trying GSE281885 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:37]\u001b[0m Trying GSE281885 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:37]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:37]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE281885'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE281885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:41]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 10\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:41]\u001b[0m Total number of processed SERIES files found is: 0\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:41]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:41]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:41]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:41]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:41]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:41]\u001b[0m Trying GSE255683 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:41]\u001b[0m Trying GSE255683 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:41]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:41]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE255683'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE255683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:43]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 20\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:43]\u001b[0m Total number of processed SERIES files found is: 0\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:43]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:43]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:43]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:43]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:43]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:43]\u001b[0m Trying GSE162256 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:43]\u001b[0m Trying GSE162256 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:43]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:55:43]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE162256'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE162256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:04]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:04]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:04]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:04]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:04]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:04]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE162256_samples\\GSE162256_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:04]\u001b[0m Trying GSE277028 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:04]\u001b[0m Trying GSE277028 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:04]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:04]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE277028'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE277028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:08]\u001b[0m Total number of processed SERIES files found is: 2\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:08]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:08]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:08]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:08]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:08]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE277028_samples\\GSE277028_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:08]\u001b[0m Trying GSE263024 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:08]\u001b[0m Trying GSE263024 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:08]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:08]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE263024'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE263024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:11]\u001b[0m Total number of processed SERIES files found is: 2\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:11]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:11]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:11]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:11]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:11]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE263024_samples\\GSE263024_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:11]\u001b[0m Trying GSE110293 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:11]\u001b[0m Trying GSE110293 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:11]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:11]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE110293'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE110293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:14]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 24\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:14]\u001b[0m Total number of processed SERIES files found is: 0\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:14]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:14]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:14]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:14]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:14]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:14]\u001b[0m Trying GSE286021 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:14]\u001b[0m Trying GSE286021 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:14]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:14]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE286021'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE286021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:16]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:16]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:16]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:16]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:16]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:16]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE286021_samples\\GSE286021_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:16]\u001b[0m Trying GSE95588 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:16]\u001b[0m Trying GSE95588 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:16]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:16]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE95588'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE95588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:21]\u001b[0m Total number of processed SERIES files found is: 2\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:21]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:21]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:21]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:21]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:21]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE95588_samples\\GSE95588_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:21]\u001b[0m Trying GSE221957 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:21]\u001b[0m Trying GSE221957 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:21]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:21]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE221957'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE221957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:23]\u001b[0m \n",
      "Total number of processed SAMPLES files found is: 16\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:23]\u001b[0m Total number of processed SERIES files found is: 0\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:23]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:23]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:23]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:23]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:23]\u001b[0m Unifying and saving of metadata... \n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:23]\u001b[0m Trying GSE144219 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:23]\u001b[0m Trying GSE144219 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:23]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:56:23]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE144219'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE144219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:16]\u001b[0m Total number of processed SERIES files found is: 5\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:16]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:16]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:16]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:16]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:16]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE144219_samples\\GSE144219_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:16]\u001b[0m Trying GSE279268 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:16]\u001b[0m Trying GSE279268 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:16]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:16]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE279268'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE279268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:30]\u001b[0m Total number of processed SERIES files found is: 8\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:30]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:30]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:30]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:30]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:30]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE279268_samples\\GSE279268_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:30]\u001b[0m Trying GSE101766 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:30]\u001b[0m Trying GSE101766 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:30]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:58:30]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE101766'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE101766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:05]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:05]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:05]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:05]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:05]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:05]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE101766_samples\\GSE101766_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:05]\u001b[0m Trying GSE94840 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:05]\u001b[0m Trying GSE94840 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:05]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:05]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE94840'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE94840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:06]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:06]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:06]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:06]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:06]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:06]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE94840_samples\\GSE94840_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:06]\u001b[0m Trying GSE231460 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:06]\u001b[0m Trying GSE231460 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:06]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:06]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE231460'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE231460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:07]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:07]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:07]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:07]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:07]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:07]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE231460_samples\\GSE231460_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:07]\u001b[0m Trying GSE244787 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:07]\u001b[0m Trying GSE244787 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:07]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:07]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE244787'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE244787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:10]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:10]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:10]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:10]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:10]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:10]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE244787_samples\\GSE244787_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:10]\u001b[0m Trying GSE95802 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:10]\u001b[0m Trying GSE95802 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:10]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:10]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE95802'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE95802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:12]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:12]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:12]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:12]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:12]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:12]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE95802_samples\\GSE95802_samples.csv won't be created\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:12]\u001b[0m Trying GSE139045 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:12]\u001b[0m Trying GSE139045 (not a file) as accession...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:12]\u001b[0m Skipped 0 accessions. Starting now.\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:12]\u001b[0m \u001b[38;5;200mProcessing accession 1 of 1: 'GSE139045'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Fetching metadata for GSE139045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:14]\u001b[0m Total number of processed SERIES files found is: 1\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:14]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:14]\u001b[0m Expanding metadata list...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:14]\u001b[0m Finished processing 1 accession(s)\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:14]\u001b[0m Cleaning soft files ...\n",
      "\u001b[1;30m[INFO]\u001b[0m \u001b[32m[23:59:14]\u001b[0m No files found. No data to save. File geofetch_metadata\\project_name\\GSE139045_samples\\GSE139045_samples.csv won't be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GSE120596: already exists at geofetch_metadata\\GSE120596, skipping.\n",
      "✅ GSE156453: already exists at geofetch_metadata\\GSE156453, skipping.\n",
      "✅ GSE279800: already exists at geofetch_metadata\\GSE279800, skipping.\n",
      "✅ GSE242272: already exists at geofetch_metadata\\GSE242272, skipping.\n",
      "✅ GSE139044: already exists at geofetch_metadata\\GSE139044, skipping.\n",
      "✅ GSE124074: already exists at geofetch_metadata\\GSE124074, skipping.\n",
      "✅ GSE245768: already exists at geofetch_metadata\\GSE245768, skipping.\n",
      "✅ GSE180857: already exists at geofetch_metadata\\GSE180857, skipping.\n",
      "✅ GSE131732: already exists at geofetch_metadata\\GSE131732, skipping.\n",
      "✅ GSE242369: already exists at geofetch_metadata\\GSE242369, skipping.\n",
      "✅ GSE110282: already exists at geofetch_metadata\\GSE110282, skipping.\n",
      "✅ GSE278083: already exists at geofetch_metadata\\GSE278083, skipping.\n",
      "✅ GSE175744: already exists at geofetch_metadata\\GSE175744, skipping.\n",
      "✅ GSE184884: already exists at geofetch_metadata\\GSE184884, skipping.\n",
      "✅ GSE38809: already exists at geofetch_metadata\\GSE38809, skipping.\n",
      "✅ GSE222593: already exists at geofetch_metadata\\GSE222593, skipping.\n",
      "✅ GSE262419: already exists at geofetch_metadata\\GSE262419, skipping.\n",
      "✅ GSE97066: already exists at geofetch_metadata\\GSE97066, skipping.\n",
      "✅ GSE281885: already exists at geofetch_metadata\\GSE281885, skipping.\n",
      "✅ GSE255683: already exists at geofetch_metadata\\GSE255683, skipping.\n",
      "✅ GSE162256: already exists at geofetch_metadata\\GSE162256, skipping.\n",
      "✅ GSE277028: already exists at geofetch_metadata\\GSE277028, skipping.\n",
      "✅ GSE263024: already exists at geofetch_metadata\\GSE263024, skipping.\n",
      "✅ GSE110293: already exists at geofetch_metadata\\GSE110293, skipping.\n",
      "✅ GSE286021: already exists at geofetch_metadata\\GSE286021, skipping.\n",
      "✅ GSE95588: already exists at geofetch_metadata\\GSE95588, skipping.\n",
      "✅ GSE221957: already exists at geofetch_metadata\\GSE221957, skipping.\n",
      "✅ GSE144219: already exists at geofetch_metadata\\GSE144219, skipping.\n",
      "✅ GSE279268: already exists at geofetch_metadata\\GSE279268, skipping.\n",
      "✅ GSE101766: already exists at geofetch_metadata\\GSE101766, skipping.\n",
      "✅ GSE94840: already exists at geofetch_metadata\\GSE94840, skipping.\n",
      "✅ GSE231460: already exists at geofetch_metadata\\GSE231460, skipping.\n",
      "✅ GSE244787: already exists at geofetch_metadata\\GSE244787, skipping.\n",
      "✅ GSE95802: already exists at geofetch_metadata\\GSE95802, skipping.\n",
      "✅ GSE139045: already exists at geofetch_metadata\\GSE139045, skipping.\n",
      "✅ Combined metadata saved to: C:\\Users\\difen\\POPPER\\geofetch_metadata\\combined_metadata.csv\n",
      "\n",
      "📋 Final Research Plan:\n",
      "Based on the provided metadata, here is the analysis of the GSE studies with drug-treated samples and matching control groups, along with the relevant details:\n",
      "\n",
      "### 1. GSE Studies with Drug-Treated Samples and Matching Control Groups\n",
      "\n",
      "#### GSE279800\n",
      "- **Drug Treatments**: Caffeine (not one of the drugs of interest but included for completeness)\n",
      "- **Control Samples**: SW480 and SW620 control samples\n",
      "- **Sample Names**:\n",
      "  - Drug-Treated: \n",
      "    - sw480_caffeine-treated_rep1\n",
      "    - sw480_caffeine-treated_rep2\n",
      "    - sw620_caffeine-treated_rep1\n",
      "    - sw620_caffeine-treated_rep2\n",
      "  - Controls:\n",
      "    - sw480_control_rep1\n",
      "    - sw480_control_rep2\n",
      "    - sw620_control_rep1\n",
      "    - sw620_control_rep2\n",
      "\n",
      "#### GSE242272\n",
      "- **Drug Treatments**: PGE2 (not one of the drugs of interest but included for completeness)\n",
      "- **Control Samples**: Vehicle controls\n",
      "- **Sample Names**:\n",
      "  - Drug-Treated:\n",
      "    - cd8_24h_pge2_1\n",
      "    - cd8_24h_pge2_2\n",
      "    - cd8_24h_pge2_3\n",
      "    - cd8_48h_pge2_1\n",
      "    - cd8_48h_pge2_2\n",
      "    - cd8_48h_pge2_3\n",
      "    - cd8_60h_pge2_1\n",
      "    - cd8_60h_pge2_2\n",
      "    - cd8_60h_pge2_3\n",
      "  - Controls:\n",
      "    - cd8_24h_vehicle1\n",
      "    - cd8_24h_vehicle2\n",
      "    - cd8_24h_vehicle3\n",
      "    - cd8_48h_vehicle1\n",
      "    - cd8_48h_vehicle2\n",
      "    - cd8_48h_vehicle3\n",
      "    - cd8_60h_vehicle1\n",
      "    - cd8_60h_vehicle2\n",
      "    - cd8_60h_vehicle3\n",
      "\n",
      "### 2. Cell Types or Tissues Used\n",
      "- **GSE279800**: Colorectal adenocarcinoma cells (SW480 and SW620)\n",
      "- **GSE242272**: Naïve CD8 T cells\n",
      "\n",
      "### 3. Treatments and Controls\n",
      "- **GSE279800**:\n",
      "  - **Treatment**: Caffeine\n",
      "  - **Controls**: SW480 and SW620 control samples (untreated)\n",
      "  \n",
      "- **GSE242272**:\n",
      "  - **Treatment**: PGE2\n",
      "  - **Controls**: Vehicle-treated Naïve CD8 samples\n",
      "\n",
      "### 4. Recommended GSEs and Sample Pairs for Differential Gene Expression\n",
      "#### Recommendation: GSE279800\n",
      "- **Sample Pairs**:\n",
      "  - SW480 Caffeine-Treated vs. SW480 Control\n",
      "    - sw480_caffeine-treated_rep1 vs. sw480_control_rep1\n",
      "    - sw480_caffeine-treated_rep2 vs. sw480_control_rep2\n",
      "  - SW620 Caffeine-Treated vs. SW620 Control\n",
      "    - sw620_caffeine-treated_rep1 vs. sw620_control_rep1\n",
      "    - sw620_caffeine-treated_rep2 vs. sw620_control_rep2\n",
      "\n",
      "**Reason for Recommendation**:\n",
      "- **Relevance**: While caffeine is not one of the primary drugs of interest (Aspirin, Ibuprofen, Naproxen, Celecoxib, Diclofenac), the study design includes both treated and control groups, making it suitable for differential expression analysis.\n",
      "- **Cell Type**: The use of colorectal adenocarcinoma cells is relevant for cancer research, and the presence of multiple replicates enhances the robustness of the analysis.\n",
      "\n",
      "#### Recommendation: GSE242272\n",
      "- **Sample Pairs**:\n",
      "  - CD8 T cells treated with PGE2 vs. Vehicle Controls\n",
      "    - cd8_24h_pge2_1 vs. cd8_24h_vehicle1\n",
      "    - cd8_24h_pge2_2 vs. cd8_24h_vehicle2\n",
      "    - cd8_24h_pge2_3 vs. cd8_24h_vehicle3\n",
      "    - cd8_48h_pge2_1 vs. cd8_48h_vehicle1\n",
      "    - cd8_48h_pge2_2 vs. cd8_48h_vehicle2\n",
      "    - cd8_48h_pge2_3 vs. cd8_48h_vehicle3\n",
      "    - cd8_60h_pge2_1 vs. cd8_60h_vehicle1\n",
      "    - cd8_60h_pge2_2 vs. cd8_60h_vehicle2\n",
      "    - cd8_60h_pge2_3 vs. cd8_60h_vehicle3\n",
      "\n",
      "**Reason for Recommendation**:\n",
      "- **Cell Type**: Naïve CD8 T cells are crucial for understanding immune responses, and the study design allows for a comprehensive analysis of gene expression changes in response to treatment.\n",
      "- **Multiple Time Points**: The inclusion of different time points (24h, 48h, 60h) provides insights into temporal changes in gene expression, which can be critical for understanding drug responses.\n",
      "\n",
      "### Conclusion\n",
      "While GSE279800 and GSE242272 do not directly involve the drugs of interest (Aspirin, Ibuprofen, Naproxen, Celecoxib, Diclofenac), they provide valuable insights into drug response mechanisms and can serve as a basis for understanding COX1-related pathways in the context of drug treatment.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    result = graph.invoke({\"query_gene\": \"COX1\"})\n",
    "    print(\"\\n📋 Final Research Plan:\")\n",
    "    print(result[\"research_plan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1daa2d5-c55a-4b6e-98df-d6d2a3b90033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c4223-11cd-4193-8949-4f12197046bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c20831b-b111-44c1-84bf-258019bfb2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9bcf2-ba92-4ecf-8d63-46e18e3dfa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c0d939b-6913-4a83-8971-35527b467c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"geofetch_metadata/combined_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a8a0e-553d-4e97-b19c-2b685058993c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "venv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
